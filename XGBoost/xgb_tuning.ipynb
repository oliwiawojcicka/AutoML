{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27bd50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score \n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb68890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(objective=\"binary:logistic\",  # klasyfikacja binarna\n",
    "    eval_metric=\"logloss\",        # metryka logloss\n",
    "    tree_method=\"hist\",           # szybka metoda histogramowa\n",
    "    booster=\"gbtree\",             # klasyczny booster\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40aa602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_param_grid = {\n",
    "    \"n_estimators\": [300, 600, 900, 1200],\n",
    "    \"max_depth\": [3, 4, 6, 8],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.1],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"min_child_weight\": [1, 2, 5, 8],\n",
    "    \"gamma\": [0.0, 1.0, 3.0],\n",
    "    \"reg_lambda\": [0.0, 1.0, 5.0, 10.0],\n",
    "    \"reg_alpha\": [0.0, 0.1, 1.0, 5.0],\n",
    "    \"scale_pos_weight\": [1.0, 2.0, 5.0],\n",
    "    \"colsample_bylevel\": [0.6, 0.8, 1.0],\n",
    "    \"grow_policy\": [\"depthwise\", \"lossguide\"],\n",
    "    \"max_bin\": [256, 512],\n",
    "    \"max_leaves\": [15, 31, 63]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eee7e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "search_space = {\n",
    "    \"n_estimators\": Integer(300, 1200),\n",
    "    \"max_depth\": Integer(3, 8),\n",
    "    \"learning_rate\": Real(0.01, 0.1, prior=\"log-uniform\"),\n",
    "    \"subsample\": Real(0.6, 1.0),\n",
    "    \"colsample_bytree\": Real(0.6, 1.0),\n",
    "    \"min_child_weight\": Integer(1, 8),\n",
    "    \"gamma\": Real(0.0, 3.0),\n",
    "    \"reg_lambda\": Real(0.0, 10.0),\n",
    "    \"reg_alpha\": Real(0.0, 5.0),\n",
    "    \"scale_pos_weight\": Real(1.0, 5.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e538b",
   "metadata": {},
   "source": [
    "# DIABETES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f72e483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = pd.read_csv(\"diabetes_transformed.csv\")   \n",
    "\n",
    "X = df_diabetes.drop('diabetes', axis=1)  \n",
    "y = df_diabetes['diabetes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1c88efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline XGB (bez tuningu) – test accuracy: 0.9730\n"
     ]
    }
   ],
   "source": [
    "baseline_xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\", n_jobs=-1, random_state=42\n",
    ")\n",
    "baseline_xgb.fit(X_train, y_train)\n",
    "baseline_acc = accuracy_score(y_test, baseline_xgb.predict(X_test))\n",
    "print(f\"Baseline XGB (bez tuningu) – test accuracy: {baseline_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72187622",
   "metadata": {},
   "source": [
    "## RANDOMIZED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "993053fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Najlepsze parametry: {'subsample': 0.6, 'scale_pos_weight': 1.0, 'reg_lambda': 5.0, 'reg_alpha': 5.0, 'n_estimators': 1200, 'min_child_weight': 5, 'max_leaves': 15, 'max_depth': 3, 'max_bin': 512, 'learning_rate': 0.03, 'grow_policy': 'depthwise', 'gamma': 0.0, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.6}\n",
      "RandomSearch – CV mean(best): 0.9720\n",
      "RandomSearch – Test accuracy: 0.9728\n",
      "RandomSearch – Liczba iteracji: 100\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=RS_param_grid,\n",
    "    n_iter=100,  \n",
    "    cv=3,  #\n",
    "    scoring='accuracy', \n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "num_iterations = len(results['params']) \n",
    "best_params_random = random_search.best_params_\n",
    "\n",
    "#najlepsze parametry:\n",
    "print(\"Najlepsze parametry:\", best_params_random)\n",
    "\n",
    "# liczba iteracji:\n",
    "num_iterations = len(results['params'])\n",
    "\n",
    "# tworzymy pełną historię wyników - opt.cv_results_ zawiera dla każdej iteracji: parametry, wynik walidacji, czasy itd.\n",
    "hist_random = pd.DataFrame(results).copy()\n",
    "hist_random[\"method\"] = \"random\"\n",
    "hist_random[\"iter\"] = np.arange(len(hist_random))\n",
    "hist_random[\"running_best\"] = np.maximum.accumulate(hist_random[\"mean_test_score\"])\n",
    "\n",
    "# test accuracy dla najlepszej konfiguracji\n",
    "y_pred_rs = random_search.predict(X_test)\n",
    "test_acc_rs = accuracy_score(y_test, y_pred_rs)\n",
    "print(f\"RandomSearch – CV mean(best): {random_search.best_score_:.4f}\")\n",
    "print(f\"RandomSearch – Test accuracy: {test_acc_rs:.4f}\")\n",
    "print(f\"RandomSearch – Liczba iteracji: {num_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11b64b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>method</th>\n",
       "      <th>iter</th>\n",
       "      <th>running_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.331953</td>\n",
       "      <td>0.015631</td>\n",
       "      <td>0.130363</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>900</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>{'subsample': 1.0, 'scale_pos_weight': 5.0, 'r...</td>\n",
       "      <td>0.950566</td>\n",
       "      <td>0.948503</td>\n",
       "      <td>0.948126</td>\n",
       "      <td>0.949065</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>49</td>\n",
       "      <td>random</td>\n",
       "      <td>0</td>\n",
       "      <td>0.949065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.078068</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.282207</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1200</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>{'subsample': 1.0, 'scale_pos_weight': 2.0, 'r...</td>\n",
       "      <td>0.969807</td>\n",
       "      <td>0.969620</td>\n",
       "      <td>0.971531</td>\n",
       "      <td>0.970319</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>23</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.711560</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.073987</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'subsample': 0.8, 'scale_pos_weight': 1.0, 'r...</td>\n",
       "      <td>0.970632</td>\n",
       "      <td>0.971307</td>\n",
       "      <td>0.972132</td>\n",
       "      <td>0.971357</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>16</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.971357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.537392</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.065690</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'subsample': 1.0, 'scale_pos_weight': 2.0, 'r...</td>\n",
       "      <td>0.968119</td>\n",
       "      <td>0.967744</td>\n",
       "      <td>0.969056</td>\n",
       "      <td>0.968307</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>32</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>0.971357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469865</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.051791</td>\n",
       "      <td>0.007606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'subsample': 1.0, 'scale_pos_weight': 5.0, 'r...</td>\n",
       "      <td>0.953867</td>\n",
       "      <td>0.955592</td>\n",
       "      <td>0.954053</td>\n",
       "      <td>0.954504</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>40</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.971357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.331953      0.015631         0.130363        0.011094   \n",
       "1       2.078068      0.011593         0.282207        0.013623   \n",
       "2       0.711560      0.017800         0.073987        0.013805   \n",
       "3       0.537392      0.001089         0.065690        0.006230   \n",
       "4       0.469865      0.013372         0.051791        0.007606   \n",
       "\n",
       "   param_subsample  param_scale_pos_weight  param_reg_lambda  param_reg_alpha  \\\n",
       "0              1.0                     5.0               5.0              5.0   \n",
       "1              1.0                     2.0               5.0              5.0   \n",
       "2              0.8                     1.0              10.0              0.0   \n",
       "3              1.0                     2.0               1.0              0.0   \n",
       "4              1.0                     5.0              10.0              0.1   \n",
       "\n",
       "   param_n_estimators  param_min_child_weight  ...  \\\n",
       "0                 900                       8  ...   \n",
       "1                1200                       5  ...   \n",
       "2                 300                       2  ...   \n",
       "3                 300                       1  ...   \n",
       "4                 300                       1  ...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'subsample': 1.0, 'scale_pos_weight': 5.0, 'r...           0.950566   \n",
       "1  {'subsample': 1.0, 'scale_pos_weight': 2.0, 'r...           0.969807   \n",
       "2  {'subsample': 0.8, 'scale_pos_weight': 1.0, 'r...           0.970632   \n",
       "3  {'subsample': 1.0, 'scale_pos_weight': 2.0, 'r...           0.968119   \n",
       "4  {'subsample': 1.0, 'scale_pos_weight': 5.0, 'r...           0.953867   \n",
       "\n",
       "   split1_test_score  split2_test_score mean_test_score  std_test_score  \\\n",
       "0           0.948503           0.948126        0.949065        0.001072   \n",
       "1           0.969620           0.971531        0.970319        0.000860   \n",
       "2           0.971307           0.972132        0.971357        0.000613   \n",
       "3           0.967744           0.969056        0.968307        0.000552   \n",
       "4           0.955592           0.954053        0.954504        0.000773   \n",
       "\n",
       "   rank_test_score  method  iter  running_best  \n",
       "0               49  random     0      0.949065  \n",
       "1               23  random     1      0.970319  \n",
       "2               16  random     2      0.971357  \n",
       "3               32  random     3      0.971357  \n",
       "4               40  random     4      0.971357  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_random.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e17e2d",
   "metadata": {},
   "source": [
    "## BAYES SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a1195d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: OrderedDict({'colsample_bytree': 0.6707487107534322, 'gamma': 0.7778311189511045, 'learning_rate': 0.010635974318114841, 'max_depth': 5, 'min_child_weight': 6, 'n_estimators': 355, 'reg_alpha': 1.8572271814891825, 'reg_lambda': 2.4096666049396416, 'scale_pos_weight': 1.9723853412464256, 'subsample': 0.6809326594353681})\n",
      "BayesSearch – CV mean(best): 0.9719\n",
      "BayesSearch – Test accuracy: 0.9729\n",
      "BayesSearch – Liczba iteracji: 60\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=xgb,\n",
    "    search_spaces=search_space,\n",
    "    n_iter=60,                \n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",      \n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    refit=True,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Najlepsze parametry:\", opt.best_params_)\n",
    "\n",
    "# tworzymy pełną historię wyników - opt.cv_results_ zawiera dla każdej iteracji: parametry, wynik walidacji, czasy itd.\n",
    "hist_bayes = pd.DataFrame(opt.cv_results_).copy()\n",
    "hist_bayes[\"method\"] = \"bayes\"\n",
    "hist_bayes[\"iter\"] = np.arange(len(hist_bayes))\n",
    "hist_bayes[\"running_best\"] = np.maximum.accumulate(hist_bayes[\"mean_test_score\"])\n",
    "\n",
    "# używamy już modelu z najlepszymi parametrami, żeby przewidzieć target i liczymy dokładność (accuracy_score).\n",
    "y_pred_bayes = opt.predict(X_test)\n",
    "test_acc_bayes = accuracy_score(y_test, y_pred_bayes)\n",
    "print(f\"BayesSearch – CV mean(best): {opt.best_score_:.4f}\")\n",
    "print(f\"BayesSearch – Test accuracy: {test_acc_bayes:.4f}\")\n",
    "print(f\"BayesSearch – Liczba iteracji: {len(hist_bayes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1207aa",
   "metadata": {},
   "source": [
    "# LOAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5df49f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_loan = pd.read_csv(\"loan_transformed.csv\")   \n",
    "\n",
    "# X = df_loan.drop('loan_status', axis=1)  \n",
    "# y = df_loan['loan_status']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff442e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_xgb = XGBClassifier(\n",
    "#     objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "#     tree_method=\"hist\", n_jobs=-1, random_state=42\n",
    "# )\n",
    "# baseline_xgb.fit(X_train, y_train)\n",
    "# baseline_acc = accuracy_score(y_test, baseline_xgb.predict(X_test))\n",
    "# print(f\"Baseline XGB (bez tuningu) – test accuracy: {baseline_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b8755b",
   "metadata": {},
   "source": [
    "## RANDOMIZED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67858e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_distributions=RS_param_grid,\n",
    "#     n_iter=50,  \n",
    "#     cv=3,  #\n",
    "#     scoring='accuracy', \n",
    "#     verbose=1,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1 \n",
    "# )\n",
    "\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# results = random_search.cv_results_\n",
    "# num_iterations = len(results['params']) \n",
    "# best_params_random = random_search.best_params_\n",
    "\n",
    "# #najlepsze parametry:\n",
    "# print(\"Najlepsze parametry:\", best_params_random)\n",
    "\n",
    "# # liczba iteracji:\n",
    "# num_iterations = len(results['params'])\n",
    "\n",
    "# # tworzymy pełną historię wyników - opt.cv_results_ zawiera dla każdej iteracji: parametry, wynik walidacji, czasy itd.\n",
    "# hist_random = pd.DataFrame(results).copy()\n",
    "# hist_random[\"method\"] = \"random\"\n",
    "# hist_random[\"iter\"] = np.arange(len(hist_random))\n",
    "# hist_random[\"running_best\"] = np.maximum.accumulate(hist_random[\"mean_test_score\"])\n",
    "\n",
    "# # test accuracy dla najlepszej konfiguracji\n",
    "# y_pred_rs = random_search.predict(X_test)\n",
    "# test_acc_rs = accuracy_score(y_test, y_pred_rs)\n",
    "# print(f\"RandomSearch – CV mean(best): {random_search.best_score_:.4f}\")\n",
    "# print(f\"RandomSearch – Test accuracy: {test_acc_rs:.4f}\")\n",
    "# print(f\"RandomSearch – Liczba iteracji: {num_iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e56d2",
   "metadata": {},
   "source": [
    "## BAYES SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "320e3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt import BayesSearchCV\n",
    "# opt = BayesSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     search_spaces=search_space,\n",
    "#     n_iter=60,                \n",
    "#     cv=5,\n",
    "#     scoring=\"accuracy\",      \n",
    "#     n_jobs=-1,\n",
    "#     random_state=42,\n",
    "#     refit=True,\n",
    "#     verbose=0,\n",
    "# )\n",
    "\n",
    "# opt.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Najlepsze parametry:\", opt.best_params_)\n",
    "\n",
    "# # tworzymy pełną historię wyników - opt.cv_results_ zawiera dla każdej iteracji: parametry, wynik walidacji, czasy itd.\n",
    "# hist_bayes = pd.DataFrame(opt.cv_results_).copy()\n",
    "# hist_bayes[\"method\"] = \"bayes\"\n",
    "# hist_bayes[\"iter\"] = np.arange(len(hist_bayes))\n",
    "# hist_bayes[\"running_best\"] = np.maximum.accumulate(hist_bayes[\"mean_test_score\"])\n",
    "\n",
    "# # używamy już modelu z najlepszymi parametrami, żeby przewidzieć target i liczymy dokładność (accuracy_score).\n",
    "# y_pred_bayes = opt.predict(X_test)\n",
    "# test_acc_bayes = accuracy_score(y_test, y_pred_bayes)\n",
    "# print(f\"BayesSearch – CV mean(best): {opt.best_score_:.4f}\")\n",
    "# print(f\"BayesSearch – Test accuracy: {test_acc_bayes:.4f}\")\n",
    "# print(f\"BayesSearch – Liczba iteracji: {len(hist_bayes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66be58e",
   "metadata": {},
   "source": [
    "# DEPRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "008c61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_depression = pd.read_csv(\"depression_transformed.csv\")   \n",
    "\n",
    "X = df_depression.drop('History of Mental Illness', axis=1)  \n",
    "y = df_depression['History of Mental Illness']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "685ed854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline XGB (bez tuningu) – test accuracy: 0.6935\n"
     ]
    }
   ],
   "source": [
    "baseline_xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\", n_jobs=-1, random_state=42\n",
    ")\n",
    "baseline_xgb.fit(X_train, y_train)\n",
    "baseline_acc = accuracy_score(y_test, baseline_xgb.predict(X_test))\n",
    "print(f\"Baseline XGB (bez tuningu) – test accuracy: {baseline_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19641d0",
   "metadata": {},
   "source": [
    "## RANDOMIZED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62e6ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Najlepsze parametry: {'subsample': 1.0, 'scale_pos_weight': 1.0, 'reg_lambda': 0.0, 'reg_alpha': 1.0, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 1.0}\n",
      "RandomSearch – CV mean(best): 0.6963\n",
      "RandomSearch – Test accuracy: 0.6945\n",
      "RandomSearch – Liczba iteracji: 50\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=RS_param_grid,\n",
    "    n_iter=50,  \n",
    "    cv=3,  #\n",
    "    scoring='accuracy', \n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "num_iterations = len(results['params']) \n",
    "best_params_random = random_search.best_params_\n",
    "\n",
    "# najlepsze parametry:\n",
    "print(\"Najlepsze parametry:\", best_params_random)\n",
    "\n",
    "# liczba iteracji:\n",
    "num_iterations = len(results['params'])\n",
    "\n",
    "# tworzymy pełną historię wyników - opt.cv_results_ zawiera dla każdej iteracji: parametry, wynik walidacji, czasy itd.\n",
    "hist_random = pd.DataFrame(results).copy()\n",
    "hist_random[\"method\"] = \"random\"\n",
    "hist_random[\"iter\"] = np.arange(len(hist_random))\n",
    "hist_random[\"running_best\"] = np.maximum.accumulate(hist_random[\"mean_test_score\"])\n",
    "\n",
    "# test accuracy dla najlepszej konfiguracji\n",
    "y_pred_rs = random_search.predict(X_test)\n",
    "test_acc_rs = accuracy_score(y_test, y_pred_rs)\n",
    "print(f\"RandomSearch – CV mean(best): {random_search.best_score_:.4f}\")\n",
    "print(f\"RandomSearch – Test accuracy: {test_acc_rs:.4f}\")\n",
    "print(f\"RandomSearch – Liczba iteracji: {num_iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f2c9e",
   "metadata": {},
   "source": [
    "## BAYES SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61abcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: OrderedDict({'colsample_bytree': 0.8115299714555839, 'gamma': 3.0, 'learning_rate': 0.02735832608348027, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 300, 'reg_alpha': 2.6644196614086435, 'reg_lambda': 10.0, 'scale_pos_weight': 1.0, 'subsample': 1.0})\n",
      "Accuracy (mean): 0.6963\n",
      "Liczba iteracji BayesSearchCV: 60\n",
      "Test accuracy: 0.6945\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=xgb,\n",
    "    search_spaces=search_space,\n",
    "    n_iter=60,                \n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",      \n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    refit=True,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Najlepsze parametry:\", opt.best_params_)\n",
    "\n",
    "# tworzymy pełną historię wyników - opt.cv_results_ zawiera dla każdej iteracji: parametry, wynik walidacji, czasy itd.\n",
    "hist_bayes = pd.DataFrame(opt.cv_results_).copy()\n",
    "hist_bayes[\"method\"] = \"bayes\"\n",
    "hist_bayes[\"iter\"] = np.arange(len(hist_bayes))\n",
    "hist_bayes[\"running_best\"] = np.maximum.accumulate(hist_bayes[\"mean_test_score\"])\n",
    "\n",
    "# używamy już modelu z najlepszymi parametrami, żeby przewidzieć target i liczymy dokładność (accuracy_score).\n",
    "y_pred_bayes = opt.predict(X_test)\n",
    "test_acc_bayes = accuracy_score(y_test, y_pred_bayes)\n",
    "print(f\"BayesSearch – CV mean(best): {opt.best_score_:.4f}\")\n",
    "print(f\"BayesSearch – Test accuracy: {test_acc_bayes:.4f}\")\n",
    "print(f\"BayesSearch – Liczba iteracji: {len(hist_bayes)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
